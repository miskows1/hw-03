{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"text-align: right;\"> &#9989; Dylan Miskowski</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSE 202 Homework 03\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Assignment instructions\n",
    "\n",
    "Work through the following assignment, making sure to follow all of the directions and answer all of the questions.\n",
    "\n",
    "There are **25 points** possible on this assignment. Point values for each part are included in the section headers.\n",
    "\n",
    "This assignment is due at 11:59 pm on **Friday October 23rd**. It should be uploaded into the \"Homework Assignments\" submission folder for Homework 3 in your D2L webpage. Submission instructions can be found at the end of the notebook.\n",
    "\n",
    "**Hint**: It is possible you are asked to do something you are not familiar with. That's why you have internet access. Do some smart searches and see what you can find! \n",
    "\n",
    "\n",
    "### Our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setting up a repository for tracking changes (3 points)\n",
    "\n",
    "For this assignment, you're going to add it to the CMSE202 repository you created in class so that you can track your progress on the assignment and preserve the final version that you turn in. In order to do this you need to:\n",
    "\n",
    "* Navigate to your `/CMSE202/repos` repository and create a new directory called `hw-03`.\n",
    "* Move this notebook into that new directory in your repository, then add it and commit it to your repository.\n",
    " * Finally, to test that everything is working, \"git push\" the file so that it ends up in your GitHub repository.\n",
    "\n",
    "Important: Make sure you've added your TA as a collaborators\\ to your respository with \"Read\" access so that we can see your assignment.\n",
    "\n",
    "* Section 001:  tuethan\n",
    "* Section 002:  Luis-Polanco\n",
    "* Section 003:  DavidRimel\n",
    "\n",
    "Also important: Make sure that the version of this notebook that you are working on is the same one that you just added to your repository! If you are working on a different copy of the noteobok, none of your changes will be tracked.\n",
    "\n",
    "\n",
    "If everything went as intended, the file should now show up on your GitHub account CMSE202 repository under the `hw-03` directory that you just created. Periodically, you'll be asked to commit your changes to the repository and push them to the remote GitHub location. Of course, you can always commit your changes more often than that, if you wish. It can be good to get into a habit of committing your changes any time you make a significant modification, or when you stop working on the project for a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Load, prepare and plot the data (5 points)\n",
    "\n",
    "In this homework we will be working with the yeast dataset and building logistic regression and k-nearest neighbors classifier class. The data file is *yeast.data* and its description is in *yeast.names*. Read the description and get a sense of the meaning of the dataset. In this part, we will load and clean up the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1 (1 point)** Load the *yeast.data* as a pandas dataframe and give appropriate names to the columns. Then drop the columns **sequence name**, **pox** and **vac**. What's the size of this dataset now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load yeast.data as df, give names to columns\n",
    "names=['Sequence name', 'mcg','gvh','alm','mit','erl','pox','vac','nuc','class']\n",
    "\n",
    "yeast=pd.read_fwf('yeast.data', names=names)\n",
    "\n",
    "#drop sequence name, pox and vac\n",
    "yeast=yeast.drop(['Sequence name','pox','vac'], axis=1)\n",
    "#size of df?\n",
    "yeast\n",
    "\n",
    "#it is now 1484 rows x 7 columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2 (1 point)** Find the number of unqiue entries in the class label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 unique entries (from yeast.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3 (1 point)** We are only interested in data with label **CYT (cytosolic or cytoskeletal)** and **MIT (mitochondrial)**. Make a new dataframe containing\n",
    "data with only these two types of labels, and redefine label **CYT** into **0**, and **MIT** into **1**. What's the size of the dataset now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only want class CYT and MIT\n",
    "#crit1=yeast['class']=='CYT'\n",
    "\n",
    "yeast2=yeast[yeast['class'].isin(['CYT','MIT'])] #OMG USE THIS FOR SELECTING 2 FROM COLUMNS FOR NOW ON!!!\n",
    "\n",
    "\n",
    "#redefine CYT to 0 and MIT to 1\n",
    "\n",
    "yeast2=yeast2.replace('CYT',0)\n",
    "yeast2=yeast2.replace('MIT',1)\n",
    "\n",
    "yeast2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4 (2 points)** Make a scatter plot including every sample in the dataset with: the mcg feature on the x-axis, the gvh feature on the y-axis, and different colors for each class label. Make your observation. Are the two classes distinguishable using only those two features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here ###\n",
    "#mcg on x, gvh on y and different colors for each label\n",
    "\n",
    "yeast2.plot(x='mcg', y='gvh',kind='scatter', c='class', cmap='Accent', colorbar=False,legend=True)\n",
    "\n",
    "\n",
    "#Q: are the classes distinguishable using only those 2 features?\n",
    "#A: no I would say we cannot easily sep them with only those 2 features. Everything is very intermingled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "In the next part we will build a logistic regression model for the data classification.\n",
    "\n",
    "## Part 3: Prepare data and build the logistic regression model (7 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1 (2 points)** Apply the \"train_test_split\" function in the *sklearn* package to split the data in 70% for training and 30% for testing.  Using common variable names like x_train, y_train, x_test and y_test might help later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_labels, test_labels= train_test_split(yeast2.drop('class', axis=1),yeast2['class'], test_size=0.3)\n",
    "#train_test_split(x,y,test_size=.25) vectors are x, labels are y\n",
    "#ensure you .drop whatever youre using for y, from x so its not \"perfect\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2 (2 points)** Perform the logistic regression. \n",
    "* Discuss your results. How well does your model fit your data? What evidence are you using to make the determination? \n",
    "* Based on the P values under \"P > |z|\", which two features **in this dataset** are the least significant and can be dropped?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log regression\n",
    "#from day09in\n",
    "logit_model = sm.Logit(train_labels, sm.add_constant(train_vectors)) #labels are y, vectors are x\n",
    "result = logit_model.fit()\n",
    "print(result.summary() )\n",
    "\n",
    "#the model does not fit that well with the data. the pseurdo rsqu is quite low\n",
    "#gvh and mit are the most significant\n",
    "#.alm, erl, nuc and mcg are the least significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3 (3 points)** Drop the two least important features found in the previous question and perform the logistic regression again. Then use the use the `sklearn.metrics` we imported at the top and run the `accuracy_score` on the 0/1 predicted label and the test labels, and print the accuracy of this model.\n",
    "\n",
    "* Discuss your results. How well does your reduced model fit your data? What evidence are you using to make the determination?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 2 worst performers\n",
    "reduced_yeast=yeast2.drop(['erl','nuc'], axis=1)\n",
    "#resort\n",
    "train_vectors, test_vectors, train_labels, test_labels= train_test_split(reduced_yeast.drop('class', axis=1),reduced_yeast['class'], test_size=0.3)\n",
    "\n",
    "#remodel\n",
    "logit_model2 = sm.Logit(train_labels, sm.add_constant(train_vectors)) #labels are y, vectors are x\n",
    "result2 = logit_model2.fit()\n",
    "print(result2.summary() )\n",
    "print(metrics.accuracy_score(train_labels, result2.predict())) #ytrue, #ypredicted, \n",
    "#My model is predicting non 0/1 values and the accuracy score doesnt like that, I am not sure how to fix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "In the next part we will be building a class that will use the k-nearest neighbors algorithm (kNN) to make predictions on the same dataset. From the previous part (logistic regression), you have selected **4 features** that are important for classification. We will **only** use those 4 features in this part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: KNN classifier, cross-validation and hyperparameter tuning (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1 (3 points)** Test drive the KNN classifier. Use the same train and test data you created in question 3.4 to build a KNN classifier with K=3. \n",
    "- make a `KNeighborsClassifier` with an argument of `n_neighbors=3`. This returns a knn classifier (let's just call it `knn`)\n",
    "- call `knn.fit` on the training data\n",
    "- use `knn.predict` on the testing data to generate the predicted values.\n",
    "- print the confusion matrix.\n",
    "- print the train and test score using `knn.score`.\n",
    "- plot the ROC curve with the diagonal (the \"chance line\") also labeled. Using `sklearn.metrics`, print the `auc` for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a KNeighborsClassifier \n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#use knn.fit on training data\n",
    "knn.fit(train_vectors, train_labels)# knn.fit(x,y) \n",
    "#QUESTION so does this just work in place?\n",
    "\n",
    "#use knn.predict on testing data to generate predicted values (aka labels)\n",
    "predictedknn=knn.predict(test_vectors) #.predict(x) returns y (predicted labels)\n",
    "\n",
    "#print confusion matrix\n",
    "#prints 2x2 matrix with columns of actual[0,1] rows of predicted [0,1] (I think)\n",
    "print(confusion_matrix(test_labels, predictedknn, labels = [0,1])) #..matrix(y_true,y_predict,labels)\n",
    "\n",
    "#print train and test score using knn.score\n",
    "print('training score is',knn.score(train_vectors,train_labels)) #.score(x=test samples,y=true labels for x) \n",
    "print('test score is',knn.score(test_vectors,test_labels)) #.score(x=test samples,y=true labels for x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ROC curve w/ diagonal (choice line ) also labeled  ALSO using sklearn.metrics print the auc for this model\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html#sklearn.metrics.plot_roc_curve\n",
    "fpr,tpr,thresholds=metrics.roc_curve(test_labels, predictedknn)\n",
    "roc_auc=metrics.auc(fpr,tpr) #area under the curve\n",
    "#plt.title('ROC curve')\n",
    "plt.plot(fpr,tpr,'b',label ='AUC = %0.2f' %roc_auc)\n",
    "\n",
    "plt.plot([0,1],[0,1],'r--',label='Chance Line') #chance line labeled in legend\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC curve of kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross-Validation\n",
    "Cross-validation is when the dataset is randomly split up into ‘k’ groups. One of the groups is used as the test set and the rest are used as the training set. The model is trained on the training set and scored on the test set. Then the process is repeated until each unique group as been used as the test set.\n",
    "For example, for 5-fold cross validation, the dataset would be split into 5 groups, and the model would be trained and tested 5 separate times so each group would get a chance to be the test set. This can be seen in the graph below.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*NyvaFiG_jXcGgOaouumYJQ.jpeg\" width=700px>\n",
    "\n",
    "The train-test-split method we used in earlier is called ‘holdout’. Cross-validation is better than using the holdout method because the holdout method score is dependent on how the data is split into train and test sets. Cross-validation gives the model an opportunity to test on multiple splits so we can get a better idea on how the model will perform on unseen data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2 (2 points)** Look up `cross_val_score` in `sklearn.model_selection`. We will still use n_neighbors=3, and  a cross-validation value of 5. `cross_val_score` takes in our k-NN model and our data as parameters. Then it splits our data into 5 groups and fits and scores our data 5 seperate times, recording the accuracy score in an array each time. We will save the accuracy scores in the cv_scores variable. Then find the average of the cv_scores, that will provide you a more accurate understanding of the accuracy of the model.\n",
    "\n",
    "* Discuss your results. How well do your models fit your data? \n",
    "* What are you using to judge that fit (i.e., how should we think about the accuracy score as a measure of quality of the model)?\n",
    "* How does the quality of the KNN model compare to logistic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your code here ###\n",
    "cv_scores=cross_val_score(knn,reduced_yeast.drop('class', axis=1),yeast2['class'])\n",
    "print('the average of the scores is', np.average(cv_scores))\n",
    "\n",
    "#answers to questions\n",
    "#A: the results seem to match with my data, the auc is 0.73 which is close to the 0.769 suggested by the cross val score\n",
    "\n",
    "#A: Im comparing the average cv score to the auc from the knn model\n",
    "\n",
    "#A: using the psuedo r-squ value as an approximation of accuracy for the log model, the knn model is much better at 0.769 compared to 0.31 in the log model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "\n",
    "Almost all machine learning models have hyperparamters. Hyperparameters are setting(s) in the model that the user needs to choose before learning takes place. For example, in k-nearest neighbors, the number of neighbors to consider  n_neighbors, is the hyperparameter. An important task in machine learning is hyperparameter tuning, which is finding the optimal hyperparmeter. We will now explore the optimal choice of this parameter for this dataset.\n",
    "\n",
    "**Question 4.3 (3 points)** Consider the range of `n_neighbors` from 1 to 100, and fix the cross-validation value to be 5. \n",
    "- For each value of n_neighbors, compute the means of the cv_scores. \n",
    "- Make a plot with the x-axis being n_neighbors, y-axis being the mean of cv_scores.\n",
    "- Find the optimal choice of n_neighbors with the largest value of the mean of cv_scores.\n",
    "\n",
    "Discuss your results\n",
    "* How does the quality of this model compare to the earlier models that you made with KNN and logisitic regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors2, test_vectors2, train_labels2, test_labels2= train_test_split(reduced_yeast.drop('class', axis=1),reduced_yeast['class'], test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I shall now do this test 100 times \n",
    "\n",
    "\n",
    "#initiallize list\n",
    "score_list=[]\n",
    "neighbors_list=[]\n",
    "double_list=[]\n",
    "#for range n_neighbors from 1 to 100\n",
    "#make a KNeighborsClassifier \n",
    "for i in range(1,101):\n",
    "    aknn=KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "    #use knn.fit on training data\n",
    "    aknn.fit(train_vectors2, train_labels2)# knn.fit(x,y) \n",
    "    #QUESTION so does this just work in place?\n",
    "\n",
    "    #use knn.predict on testing data to generate predicted values (aka labels)\n",
    "    predictedknn2=aknn.predict(test_vectors2) #.predict(x) returns y (predicted labels)\n",
    "    #generate cv score and add to list\n",
    "    cv_score=cross_val_score(aknn,reduced_yeast.drop('class', axis=1),reduced_yeast['class'])\n",
    "    score_list.append([np.average(cv_score)])\n",
    "    neighbors_list.append(i)\n",
    "    double_list.append([str(i),[np.average(cv_score)]])\n",
    "    #returns score_list, [average score] and neighbors_list[#neighbors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x neighbors, y mean of cv scores\n",
    "plt.plot(neighbors_list,score_list)\n",
    "print(max(score_list))\n",
    "\n",
    "#the best value is at 13 neighbors and is 0.8245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use a more efficient method: `GridSearchCV` in `sklearn.model_selection` to find the optimal n_neighbors.\n",
    "\n",
    "**Question 4.4 (2 points)** Look up `GridSearchCV` in `sklearn.model_selection`. We will still use a cross-validation value of 5.  Use `best_params_` in `GridSearchCV` to find the optimal n_neighbors. Does it agree with the results from question 4.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the list into a dict, because this premadona of a function requires it\n",
    "double_dict=dict(double_list)\n",
    "print(double_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf=GridSearchCV(aknn,double_dict,cv=5, return_train_score=True) #param grid are values you want to test and compare aka hyperparamets we are trying to optimize\n",
    "#aka n_neighbors\n",
    "#OK SO THE PARAM GRID ITEMS NEEDS ENTRIES TO BE A LIST, EVEN A LIST OF 1. KCOOL. \n",
    "clf.fit(train_vectors2,train_labels2)\n",
    "#OK SO PARAMS MUST BE STR. KCOOL.\n",
    "\n",
    "#I have no idea if this agrees or disagrees with the other fcn, I have tried changing things to str and reading the documentation for the GridSearchCV fcn but I have NO idea what it is asking for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Assignment wrap-up\n",
    "\n",
    "Please fill out the form that appears when you run the code below.  **You must completely fill this out in order to receive credit for the assignment!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\n",
    "\"\"\"\n",
    "<iframe \n",
    "\tsrc=\"https://docs.google.com/forms/d/e/1FAIpQLSc0IBD2mdn4TcRyi-KNXVtS3aEg6U4mOFq2MOciLQyEP4bg1w/viewform?usp=sf_link\" \n",
    "\twidth=\"800px\" \n",
    "\theight=\"600px\" \n",
    "\tframeborder=\"0\" \n",
    "\tmarginheight=\"0\" \n",
    "\tmarginwidth=\"0\">\n",
    "\tLoading...\n",
    "</iframe>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congratulations, you're done!\n",
    "\n",
    "Submit this assignment by uploading it to the course Desire2Learn web page.  Go to the \"Homework Assignments\" folder, find the dropbox link for Homework 3, and upload your notebook **and the script you wrote**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
